{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788aa67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import gzip\n",
    "from pathlib import Path\n",
    "from lxml import etree\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d7f527",
   "metadata": {},
   "outputs": [],
   "source": [
    "papers = (\n",
    "    pl.read_ndjson(\"../data/papers.jsonl\")\n",
    "    .with_columns(pl.col(\"published\").str.to_date(format=\"%Y-%m-%d\", exact=False))\n",
    ")\n",
    "papers['published'].dt.year().value_counts().sort('published').plot.bar(x='published', y='count')\n",
    "\n",
    "times_cited = papers[['citations']].explode('citations').unnest('citations').filter(pl.col('arxiv_id').is_not_null())['arxiv_id'].value_counts(sort=True).rename({'count': 'times_cited'})\n",
    "papers = papers.join(times_cited, on='arxiv_id', how='left')\n",
    "\n",
    "with pl.Config(fmt_str_lengths=1000):\n",
    "    display(\n",
    "        papers.sort(['depth', 'times_cited'], descending=[False, True], nulls_last=True).head(20)[['arxiv_id', 'title', 'published','authors', 'depth', 'times_cited']]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b82087",
   "metadata": {},
   "outputs": [],
   "source": [
    "papers['authors'].explode().value_counts().sort('count', descending=True).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0105af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = (\n",
    "    papers\n",
    "    .rename({'arxiv_id': 'source_arxiv_id', 'title': 'source_title', 'authors': 'source_authors'})\n",
    "    .explode('citations').unnest('citations')\n",
    "    .filter(pl.col('arxiv_id').is_not_null() & pl.col('num_references') > 0)\n",
    "    .explode('reference_contexts')\n",
    "    .drop('categories', 'pdf_url', 'arxiv_url', 'xml_file_path', 'num_references', 'num_citations', 'num_arxiv_citations', 'depth', 'processing_timestamp')\n",
    "    .join(papers[['arxiv_id']], on='arxiv_id', how='inner')\n",
    ")\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f37757",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = train_data.sample(1).to_dicts()[0]\n",
    "print(f\"[{sample['arxiv_id']}] {sample['published']}. {sample['authors']}\")\n",
    "print(sample['source_title'])\n",
    "print('-' * 32)\n",
    "\n",
    "print(sample['abstract'])\n",
    "print('-' * 32)\n",
    "print(sample['reference_contexts'])\n",
    "\n",
    "print('='*32)\n",
    "cited_info = papers.filter(pl.col('arxiv_id') == sample['arxiv_id']).to_dicts()[0]\n",
    "print(f\"[{cited_info['arxiv_id']}] {cited_info['published']}. {cited_info['authors']}\")\n",
    "print(cited_info['title'])\n",
    "print(cited_info['abstract'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d742c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "matched_citations = (\n",
    "    papers[['arxiv_id', 'title', 'authors', 'citations']]\n",
    "    .with_columns(\n",
    "        pl.col('citations').list.eval(pl.element().struct['arxiv_id']).list.drop_nulls().list.unique().alias('cited_papers'),\n",
    "        pl.col('citations').list.eval(pl.element().struct['authors']).list.eval(pl.element().explode().drop_nulls()).list.unique().alias('cited_authors')\n",
    "    )\n",
    ")\n",
    "\n",
    "author_citations: dict[tuple[str, str], int] = {}\n",
    "for citing_authors, cited_authors in matched_citations[['authors', 'cited_authors']].iter_rows():\n",
    "    for citing_author in citing_authors:\n",
    "        for cited_author in cited_authors:\n",
    "            author_citations[(citing_author, cited_author)] = author_citations.get((citing_author, cited_author), 0) + 1\n",
    "\n",
    "author_citations = [\n",
    "    {'citing_author': citing_author, 'cited_author': cited_author, 'count': count}\n",
    "    for (citing_author, cited_author), count in author_citations.items()\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea42f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.DataFrame(author_citations).filter(pl.col('citing_author') == pl.col('cited_author')).sort('count', descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98e57cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "paper = papers.sample(1).to_dicts()[0]\n",
    "print(f\"Source Paper {paper['arxiv_id']}: {paper['title']}\")\n",
    "\n",
    "citations = paper['citations']\n",
    "\n",
    "arxiv_citations_with_context = [c for c in citations if c['arxiv_id'] and c['reference_contexts']]\n",
    "\n",
    "print(\"Referred to:\")\n",
    "for c in arxiv_citations_with_context:\n",
    "    crawled = c['arxiv_id'] in papers['arxiv_id']\n",
    "    c.pop('citation_id')\n",
    "    c['crawled'] = crawled\n",
    "    if crawled:\n",
    "        print(json.dumps(c, indent=2))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea79a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load and parse the gzipped TEI XML --\n",
    "arxiv_id = \"2212.09748\"\n",
    "xml_path = Path(f\"../data/xml_docs/{arxiv_id}.xml.gz\")\n",
    "with gzip.open(xml_path, \"rb\") as f:\n",
    "    data = f.read()\n",
    "\n",
    "parser = etree.XMLParser(recover=True)\n",
    "root = etree.fromstring(data, parser=parser)\n",
    "\n",
    "NS = {\"tei\": \"http://www.tei-c.org/ns/1.0\"}\n",
    "tei_text = lambda el: \" \".join(\" \".join(el.itertext()).split()) if el is not None else \"\"\n",
    "\n",
    "\n",
    "# --- Quick helpers ---\n",
    "def get_title(root):\n",
    "    xp = [\n",
    "        \".//tei:teiHeader/tei:fileDesc/tei:titleStmt/tei:title\",\n",
    "        \".//tei:fileDesc/tei:sourceDesc//tei:biblStruct/tei:analytic/tei:title[@type='main']\",\n",
    "        \".//tei:fileDesc/tei:sourceDesc//tei:biblStruct/tei:monogr/tei:title\",\n",
    "    ]\n",
    "    for path in xp:\n",
    "        node = root.find(path, NS)\n",
    "        if node is not None and tei_text(node):\n",
    "            return tei_text(node)\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_abstract(root):\n",
    "    node = root.find(\".//tei:text/tei:front/tei:abstract\", NS) or root.find(\".//tei:profileDesc/tei:abstract\", NS)\n",
    "    return tei_text(node) if node is not None else None\n",
    "\n",
    "\n",
    "def iter_sections(root):\n",
    "    \"\"\"Yield (path, level, title, type, text) for each section/subsection.\"\"\"\n",
    "    body = root.find(\".//tei:text/tei:body\", NS)\n",
    "    if body is None:\n",
    "        return\n",
    "    stack = [(body, 0, [])]\n",
    "    while stack:\n",
    "        node, level, path = stack.pop()\n",
    "        divs = list(node.findall(\"./tei:div\", NS))\n",
    "        for i, div in enumerate(divs, 1):\n",
    "            new_path = path + [i]\n",
    "            title = tei_text(div.find(\"./tei:head\", NS))\n",
    "            paras = [tei_text(p) for p in div.findall(\"./tei:p\", NS)]\n",
    "            text = \"\\n\\n\".join([p for p in paras if p])\n",
    "            yield {\n",
    "                \"path\": \".\".join(map(str, new_path)),\n",
    "                \"level\": level + 1,\n",
    "                \"title\": title,\n",
    "                \"type\": div.get(\"type\"),\n",
    "                \"text\": text,\n",
    "            }\n",
    "            # Push children for recursion\n",
    "            for child in reversed(div.findall(\"./tei:div\", NS)):\n",
    "                stack.append((child, level + 1, new_path))\n",
    "\n",
    "\n",
    "# --- Extract ---\n",
    "title = get_title(root)\n",
    "abstract = get_abstract(root)\n",
    "sections = list(iter_sections(root))\n",
    "\n",
    "print(title)\n",
    "print(abstract)\n",
    "print([s['title'] for s in sections])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
